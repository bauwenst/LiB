{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "corpus_brtext = []\n",
    "corpus_brtext_test = []\n",
    "sents_set = set()\n",
    "\n",
    "with open('br-text.txt') as f:\n",
    "    for l in f.readlines():\n",
    "        sents_set.add(l.replace('\\n',''))\n",
    "        \n",
    "sents_set = list(sents_set)        \n",
    "sents1 = []\n",
    "for i in sents_set:\n",
    "    sent = i.split(' ')\n",
    "    sents1.append(sent)\n",
    "\n",
    "for _ in range(400):\n",
    "    corpus_brtext.append([])\n",
    "    for i in set(np.random.choice(range(len(sents1)),200)):\n",
    "        corpus_brtext[-1].append(sents1[i])\n",
    "    corpus_brtext[-1] = [[''.join(j) for j in corpus_brtext[-1]], corpus_brtext[-1]]\n",
    "\n",
    "sents2 = []\n",
    "for i in sents_set[int(len(sents_set)*0.9):]:\n",
    "    sent = i.split(' ')\n",
    "    sents2.append(sent)\n",
    "sents2 = [[''.join(j) for j in sents2], sents2]\n",
    "corpus_brtext_test.append(sents2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run LiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t  MemLength: 131\n",
      "[B] Precision: 34.67% \t Recall: 95.18% \t F1: 50.83%\n",
      "[L] Precision: 8.20% \t Recall: 22.52% \t F1: 12.02%\n",
      "\n",
      "100\t  MemLength: 710\n",
      "[B] Precision: 65.59% \t Recall: 91.90% \t F1: 76.55%\n",
      "[L] Precision: 41.72% \t Recall: 58.45% \t F1: 48.69%\n",
      "\n",
      "200\t  MemLength: 899\n",
      "[B] Precision: 70.42% \t Recall: 91.44% \t F1: 79.56%\n",
      "[L] Precision: 48.25% \t Recall: 62.65% \t F1: 54.52%\n",
      "\n",
      "300\t  MemLength: 994\n",
      "[B] Precision: 74.84% \t Recall: 91.28% \t F1: 82.25%\n",
      "[L] Precision: 56.06% \t Recall: 68.39% \t F1: 61.62%\n",
      "\n",
      "400\t  MemLength: 1096\n",
      "[B] Precision: 74.87% \t Recall: 91.36% \t F1: 82.30%\n",
      "[L] Precision: 54.61% \t Recall: 66.63% \t F1: 60.02%\n",
      "\n",
      "500\t  MemLength: 1162\n",
      "[B] Precision: 74.61% \t Recall: 90.29% \t F1: 81.70%\n",
      "[L] Precision: 54.23% \t Recall: 65.63% \t F1: 59.39%\n",
      "\n",
      "600\t  MemLength: 1215\n",
      "[B] Precision: 74.96% \t Recall: 89.95% \t F1: 81.77%\n",
      "[L] Precision: 53.11% \t Recall: 63.72% \t F1: 57.93%\n",
      "\n",
      "700\t  MemLength: 1256\n",
      "[B] Precision: 76.73% \t Recall: 90.37% \t F1: 82.99%\n",
      "[L] Precision: 57.42% \t Recall: 67.62% \t F1: 62.10%\n",
      "\n",
      "800\t  MemLength: 1292\n",
      "[B] Precision: 76.18% \t Recall: 90.94% \t F1: 82.91%\n",
      "[L] Precision: 55.52% \t Recall: 66.28% \t F1: 60.43%\n",
      "\n",
      "900\t  MemLength: 1321\n",
      "[B] Precision: 77.66% \t Recall: 90.21% \t F1: 83.47%\n",
      "[L] Precision: 57.35% \t Recall: 66.63% \t F1: 61.64%\n",
      "\n",
      "1000\t  MemLength: 1365\n",
      "[B] Precision: 77.80% \t Recall: 90.44% \t F1: 83.65%\n",
      "[L] Precision: 57.51% \t Recall: 66.86% \t F1: 61.83%\n",
      "\n",
      "1100\t  MemLength: 1400\n",
      "[B] Precision: 79.77% \t Recall: 89.11% \t F1: 84.18%\n",
      "[L] Precision: 59.75% \t Recall: 66.74% \t F1: 63.06%\n",
      "\n",
      "1200\t  MemLength: 1425\n",
      "[B] Precision: 78.18% \t Recall: 89.03% \t F1: 83.25%\n",
      "[L] Precision: 57.47% \t Recall: 65.44% \t F1: 61.20%\n",
      "\n",
      "1300\t  MemLength: 1456\n",
      "[B] Precision: 78.78% \t Recall: 88.53% \t F1: 83.37%\n",
      "[L] Precision: 57.96% \t Recall: 65.14% \t F1: 61.34%\n",
      "\n",
      "1400\t  MemLength: 1477\n",
      "[B] Precision: 78.43% \t Recall: 88.42% \t F1: 83.13%\n",
      "[L] Precision: 57.48% \t Recall: 64.79% \t F1: 60.92%\n",
      "\n",
      "1500\t  MemLength: 1501\n",
      "[B] Precision: 80.57% \t Recall: 89.22% \t F1: 84.67%\n",
      "[L] Precision: 60.89% \t Recall: 67.43% \t F1: 63.99%\n",
      "\n",
      "1600\t  MemLength: 1507\n",
      "[B] Precision: 82.14% \t Recall: 88.61% \t F1: 85.25%\n",
      "[L] Precision: 63.11% \t Recall: 68.08% \t F1: 65.50%\n",
      "\n",
      "1700\t  MemLength: 1528\n",
      "[B] Precision: 81.54% \t Recall: 88.30% \t F1: 84.79%\n",
      "[L] Precision: 61.95% \t Recall: 67.09% \t F1: 64.42%\n",
      "\n",
      "1800\t  MemLength: 1546\n",
      "[B] Precision: 81.16% \t Recall: 89.07% \t F1: 84.93%\n",
      "[L] Precision: 61.62% \t Recall: 67.62% \t F1: 64.48%\n",
      "\n",
      "1900\t  MemLength: 1563\n",
      "[B] Precision: 82.59% \t Recall: 89.37% \t F1: 85.85%\n",
      "[L] Precision: 64.50% \t Recall: 69.80% \t F1: 67.05%\n",
      "\n",
      "2000\t  MemLength: 1568\n",
      "[B] Precision: 81.69% \t Recall: 88.34% \t F1: 84.89%\n",
      "[L] Precision: 61.79% \t Recall: 66.82% \t F1: 64.21%\n",
      "\n",
      "2100\t  MemLength: 1579\n",
      "[B] Precision: 82.38% \t Recall: 89.56% \t F1: 85.82%\n",
      "[L] Precision: 63.96% \t Recall: 69.53% \t F1: 66.63%\n",
      "\n",
      "2200\t  MemLength: 1597\n",
      "[B] Precision: 81.95% \t Recall: 89.37% \t F1: 85.50%\n",
      "[L] Precision: 63.51% \t Recall: 69.27% \t F1: 66.26%\n",
      "\n",
      "2300\t  MemLength: 1606\n",
      "[B] Precision: 81.59% \t Recall: 88.11% \t F1: 84.73%\n",
      "[L] Precision: 61.13% \t Recall: 66.02% \t F1: 63.48%\n",
      "\n",
      "2400\t  MemLength: 1625\n",
      "[B] Precision: 81.65% \t Recall: 87.96% \t F1: 84.69%\n",
      "[L] Precision: 61.85% \t Recall: 66.63% \t F1: 64.15%\n",
      "\n",
      "2500\t  MemLength: 1637\n",
      "[B] Precision: 80.95% \t Recall: 87.23% \t F1: 83.97%\n",
      "[L] Precision: 59.28% \t Recall: 63.88% \t F1: 61.49%\n",
      "\n",
      "2600\t  MemLength: 1643\n",
      "[B] Precision: 81.76% \t Recall: 89.45% \t F1: 85.43%\n",
      "[L] Precision: 63.24% \t Recall: 69.19% \t F1: 66.08%\n",
      "\n",
      "2700\t  MemLength: 1652\n",
      "[B] Precision: 81.53% \t Recall: 89.41% \t F1: 85.29%\n",
      "[L] Precision: 62.81% \t Recall: 68.88% \t F1: 65.71%\n",
      "\n",
      "2800\t  MemLength: 1663\n",
      "[B] Precision: 81.14% \t Recall: 88.95% \t F1: 84.87%\n",
      "[L] Precision: 61.02% \t Recall: 66.90% \t F1: 63.82%\n",
      "\n",
      "2900\t  MemLength: 1679\n",
      "[B] Precision: 82.34% \t Recall: 89.98% \t F1: 85.99%\n",
      "[L] Precision: 64.08% \t Recall: 70.03% \t F1: 66.92%\n",
      "\n",
      "3000\t  MemLength: 1695\n",
      "[B] Precision: 81.86% \t Recall: 88.30% \t F1: 84.96%\n",
      "[L] Precision: 62.05% \t Recall: 66.93% \t F1: 64.40%\n",
      "\n",
      "3100\t  MemLength: 1713\n",
      "[B] Precision: 82.86% \t Recall: 89.26% \t F1: 85.94%\n",
      "[L] Precision: 64.90% \t Recall: 69.92% \t F1: 67.32%\n",
      "\n",
      "3200\t  MemLength: 1721\n",
      "[B] Precision: 82.30% \t Recall: 87.96% \t F1: 85.03%\n",
      "[L] Precision: 62.27% \t Recall: 66.55% \t F1: 64.34%\n",
      "\n",
      "3300\t  MemLength: 1730\n",
      "[B] Precision: 81.94% \t Recall: 88.80% \t F1: 85.23%\n",
      "[L] Precision: 63.10% \t Recall: 68.39% \t F1: 65.64%\n",
      "\n",
      "3400\t  MemLength: 1742\n",
      "[B] Precision: 82.61% \t Recall: 88.26% \t F1: 85.34%\n",
      "[L] Precision: 63.33% \t Recall: 67.66% \t F1: 65.42%\n",
      "\n",
      "3500\t  MemLength: 1743\n",
      "[B] Precision: 82.68% \t Recall: 89.26% \t F1: 85.85%\n",
      "[L] Precision: 63.95% \t Recall: 69.04% \t F1: 66.40%\n",
      "\n",
      "3600\t  MemLength: 1757\n",
      "[B] Precision: 81.54% \t Recall: 87.12% \t F1: 84.24%\n",
      "[L] Precision: 60.68% \t Recall: 64.83% \t F1: 62.69%\n",
      "\n",
      "3700\t  MemLength: 1765\n",
      "[B] Precision: 82.27% \t Recall: 86.54% \t F1: 84.35%\n",
      "[L] Precision: 61.45% \t Recall: 64.64% \t F1: 63.00%\n",
      "\n",
      "3800\t  MemLength: 1769\n",
      "[B] Precision: 82.55% \t Recall: 87.35% \t F1: 84.88%\n",
      "[L] Precision: 62.21% \t Recall: 65.83% \t F1: 63.97%\n",
      "\n",
      "3900\t  MemLength: 1786\n",
      "[B] Precision: 81.79% \t Recall: 88.61% \t F1: 85.06%\n",
      "[L] Precision: 61.50% \t Recall: 66.63% \t F1: 63.96%\n",
      "\n",
      "4000\t  MemLength: 1792\n",
      "[B] Precision: 82.62% \t Recall: 87.39% \t F1: 84.93%\n",
      "[L] Precision: 62.49% \t Recall: 66.09% \t F1: 64.24%\n",
      "\n",
      "4100\t  MemLength: 1798\n",
      "[B] Precision: 83.14% \t Recall: 86.93% \t F1: 84.99%\n",
      "[L] Precision: 63.22% \t Recall: 66.09% \t F1: 64.62%\n",
      "\n",
      "4200\t  MemLength: 1807\n",
      "[B] Precision: 82.67% \t Recall: 87.35% \t F1: 84.94%\n",
      "[L] Precision: 62.66% \t Recall: 66.21% \t F1: 64.39%\n",
      "\n",
      "4300\t  MemLength: 1815\n",
      "[B] Precision: 82.29% \t Recall: 88.46% \t F1: 85.26%\n",
      "[L] Precision: 62.91% \t Recall: 67.62% \t F1: 65.18%\n",
      "\n",
      "4400\t  MemLength: 1814\n",
      "[B] Precision: 80.96% \t Recall: 88.07% \t F1: 84.36%\n",
      "[L] Precision: 60.26% \t Recall: 65.56% \t F1: 62.80%\n",
      "\n",
      "4500\t  MemLength: 1814\n",
      "[B] Precision: 81.13% \t Recall: 87.77% \t F1: 84.32%\n",
      "[L] Precision: 60.35% \t Recall: 65.29% \t F1: 62.72%\n",
      "\n",
      "4600\t  MemLength: 1823\n",
      "[B] Precision: 82.34% \t Recall: 88.42% \t F1: 85.27%\n",
      "[L] Precision: 63.12% \t Recall: 67.78% \t F1: 65.36%\n",
      "\n",
      "4700\t  MemLength: 1831\n",
      "[B] Precision: 79.83% \t Recall: 86.39% \t F1: 82.98%\n",
      "[L] Precision: 56.38% \t Recall: 61.01% \t F1: 58.60%\n",
      "\n",
      "4800\t  MemLength: 1830\n",
      "[B] Precision: 82.14% \t Recall: 87.92% \t F1: 84.93%\n",
      "[L] Precision: 62.00% \t Recall: 66.36% \t F1: 64.11%\n",
      "\n",
      "4900\t  MemLength: 1844\n",
      "[B] Precision: 81.50% \t Recall: 86.58% \t F1: 83.97%\n",
      "[L] Precision: 60.06% \t Recall: 63.80% \t F1: 61.87%\n",
      "\n",
      "5000\t  MemLength: 1847\n",
      "[B] Precision: 82.53% \t Recall: 86.31% \t F1: 84.38%\n",
      "[L] Precision: 61.70% \t Recall: 64.53% \t F1: 63.08%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import model\n",
    "import importlib\n",
    "importlib.reload(model)\n",
    "\n",
    "model.life = 10\n",
    "model.max_len = 12\n",
    "model.memory_in = 0.25\n",
    "model.memory_out = 0.0001\n",
    "model.update_rate = 0.2\n",
    "\n",
    "model.mini_gap = 1\n",
    "model.use_skip=False\n",
    "\n",
    "memory = model.TrieList()\n",
    "\n",
    "corpus_train = corpus_brtext\n",
    "corpus_test = corpus_brtext_test\n",
    "\n",
    "model.init(memory, corpus_train[0][0]) # init the Lexicon memory with some unigrams in corpus\n",
    "\n",
    "for epoch_id in range(5001):\n",
    "    model.run(epoch_id, memory, corpus_train, corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the head entities in Lexicon memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you',\n",
       " 'for',\n",
       " 'and',\n",
       " 'canyou',\n",
       " 'the',\n",
       " 'what',\n",
       " 'wanna',\n",
       " \"what's\",\n",
       " 'yeah',\n",
       " 'it',\n",
       " 'your',\n",
       " 'we',\n",
       " 'he',\n",
       " 'that',\n",
       " 'put',\n",
       " 'thisis',\n",
       " 'feel',\n",
       " 'youcan',\n",
       " \"that's\",\n",
       " 'with',\n",
       " 'this',\n",
       " 'his',\n",
       " \"he's\",\n",
       " 'see',\n",
       " 'okay',\n",
       " 'now',\n",
       " 'to',\n",
       " \"there's\",\n",
       " 'can',\n",
       " 'look',\n",
       " 'youwanna',\n",
       " 'youwant',\n",
       " 'is',\n",
       " 'here',\n",
       " 'isit',\n",
       " 'in',\n",
       " \"don't\",\n",
       " 'at',\n",
       " \"here's\",\n",
       " \"let's\",\n",
       " \"you're\",\n",
       " \"'s\",\n",
       " 'on',\n",
       " 'no',\n",
       " 'have',\n",
       " 'not',\n",
       " 'thoseare',\n",
       " 'get',\n",
       " 'my',\n",
       " 'gonna']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the chunk segmentation result and the subchunk segmentation result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "chunks\n",
      "---\n",
      " \t can you \t make \t a tower \t with \t what you \t have \t\n",
      " \t canyou \t make \t atower \t with \t whatyou \t have \t\n",
      "\n",
      "you can \t get down \t by \t yourself \t see she has \t her \t\n",
      "youcan \t getdown \t b y \t your self \t seeshehas \t her \t\n",
      "\n",
      "pajamas \t on \t don't \t honey \t you'll \t break \t it \t\n",
      "p a j am as \t on \t don't \t honey \t you 'll \t br eak \t it \t\n",
      "\n",
      "numbers \t are those \t slippers \t no what \t that's a \t\n",
      "numbers \t arethose \t s l i pper s \t now hat \t that'sa \t\n",
      "\n",
      "---\n",
      "subchunks\n",
      "---\n",
      " \t can you \t make \t a tower \t with \t what \t you \t\n",
      " \t canyou \t make \t atower \t with \t what \t you \t\n",
      "\n",
      "have \t you can \t get \t down \t by \t yourself \t\n",
      "have \t youcan \t get \t down \t b y \t your self \t\n",
      "\n",
      "see she has \t her \t pajamas \t on \t don't \t honey \t\n",
      "seeshehas \t her \t p a j am as \t on \t don't \t honey \t\n",
      "\n",
      "you'll \t break \t it \t numbers \t are \t those \t slippers \t\n",
      "you 'll \t br eak \t it \t numbers \t are \t those \t s l i p per s \t\n",
      "\n",
      "no what \t that's \t a \t bird \t which \t color \t\n",
      "now h at \t that's \t a \t bird \t which \t color \t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article, article_raw = corpus_train[2]\n",
    "onset, end = 10, 20\n",
    "print('---\\nchunks\\n---')\n",
    "model.show_result(memory, article_raw[onset:end], article[onset:end], decompose=False)\n",
    "print('---\\nsubchunks\\n---')\n",
    "model.show_result(memory, article_raw[onset:end], article[onset:end], decompose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
